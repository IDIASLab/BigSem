{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a357468",
   "metadata": {},
   "source": [
    "# SparkKG-ML Tutorial\n",
    "\n",
    "Welcome to this tutorial on **SparkKG-ML**, a Python library designed to facilitate machine learning with Spark on semantic web and knowledge graph data.\n",
    "\n",
    "In this notebook, we will walk through the installation of SparkKG-ML, and demonstrate some of the key functionalities including data acquisition from SPARQL endpoints, feature engineering, vectorization, and semantification. We will also create a simple pipeline and evaluate the results.\n",
    "\n",
    "## Installation\n",
    "\n",
    "We begin by installing the SparkKG-ML library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install sparkkgml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b0ef3",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "\n",
    "We will retrieve data from a SPARQL endpoint and convert it into a Spark DataFrame using the `getDataFrame` function. Here's how you can achieve that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sparkkgml.data_acquisition import DataAcquisition\n",
    "\n",
    "# Create an instance of DataAcquisition\n",
    "dataAcquisitionObject = DataAcquisition()\n",
    "\n",
    "# Specify the SPARQL endpoint and query\n",
    "endpoint = \"https://recipekg.arcc.albany.edu/RecipeKG\"\n",
    "query ='''\n",
    "    PREFIX schema: <https://schema.org/>\n",
    "    PREFIX recipeKG:<http://purl.org/recipekg/>\n",
    "    SELECT  ?recipe\n",
    "    WHERE { ?recipe a schema:Recipe. }\n",
    "    LIMIT 3\n",
    "'''\n",
    "\n",
    "# Retrieve the data as a Spark DataFrame\n",
    "spark_df = dataAcquisitionObject.getDataFrame(endpoint=endpoint, query=query)\n",
    "spark_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646b987",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "After acquiring the data, we can use the `getFeatures` function to extract features and their descriptions from the Spark DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b009366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sparkkgml.feature_engineering import FeatureEngineering\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# Clean the data\n",
    "spark_df = spark_df.withColumn(\"recipe\", regexp_replace('recipe', 'http://purl.org/recipekg/recipe/', ''))\n",
    "\n",
    "# Create an instance of FeatureEngineering\n",
    "featureEngineeringObject = FeatureEngineering()\n",
    "\n",
    "# Extract features\n",
    "df2, features = featureEngineeringObject.getFeatures(spark_df)\n",
    "df2.show()\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11afebaf",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "Next, we can vectorize the features we extracted using the `vectorize` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c188dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sparkkgml.vectorization import Vectorization\n",
    "\n",
    "# Create an instance of Vectorization\n",
    "vectorizationObject = Vectorization()\n",
    "\n",
    "# Vectorize the DataFrame\n",
    "digitized_df = vectorizationObject.vectorize(df2, features)\n",
    "digitized_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e250b",
   "metadata": {},
   "source": [
    "## Semantification\n",
    "\n",
    "Finally, we will use the `semantify` function to convert the DataFrame results into RDF data in Turtle format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac69b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sparkkgml.semantification import Semantification\n",
    "\n",
    "# Create an instance of Semantification\n",
    "semantificationObject = Semantification()\n",
    "\n",
    "# Semantify the data\n",
    "semantificationObject.semantify(df2, namespace=\"http://example.com/\", exp_uri=\"recipe\", exp_label=\"calorie\", exp_prediction=\"category\", dest=\"output.ttl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d018e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we installed SparkKG-ML, retrieved data from a SPARQL endpoint, performed feature engineering, vectorized the data, and finally semantified the machine learning results. This demonstrates how SparkKG-ML facilitates a complete machine learning pipeline with semantic web and knowledge graph data.\n",
    "\n",
    "Feel free to explore the additional functionalities in the SparkKG-ML documentation.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
