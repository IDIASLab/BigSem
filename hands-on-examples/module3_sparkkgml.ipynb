{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a357468",
      "metadata": {
        "id": "4a357468"
      },
      "source": [
        "# SparkKG-ML Tutorial\n",
        "\n",
        "Welcome to this tutorial on **SparkKG-ML**, a Python library designed to facilitate machine learning with Spark on semantic web and knowledge graph data.\n",
        "\n",
        "In this notebook, we will walk through the installation of SparkKG-ML, and demonstrate some of the key functionalities including data acquisition from SPARQL endpoints, feature engineering, vectorization, and semantification. We will also create a simple pipeline and evaluate the results.\n",
        "\n",
        "## Installation\n",
        "\n",
        "We begin by installing the SparkKG-ML library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a154006b",
      "metadata": {
        "id": "a154006b"
      },
      "outputs": [],
      "source": [
        "!pip install sparkkgml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db8b0ef3",
      "metadata": {
        "id": "db8b0ef3"
      },
      "source": [
        "## Data Acquisition\n",
        "\n",
        "We will retrieve data from out ttl file and convert it into a Spark DataFrame using the `getDataFrame` function. Here's how you can achieve that.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparkkgml.data_acquisition import DataAcquisition\n",
        "\n",
        "# Create an instance of DataAcquisition\n",
        "dataAcquisitionObject = DataAcquisition()\n",
        "\n",
        "query ='''\n",
        "    PREFIX schema: <https://schema.org/>\n",
        "    PREFIX recipeKG:<http://purl.org/recipekg/>\n",
        "    SELECT  ?recipe\n",
        "    WHERE { ?recipe a schema:Recipe. }\n",
        "    LIMIT 3\n",
        "'''\n",
        "spark_df = dataAcquisitionObject.query_local_rdf(\"recipekg_100.ttl\",'ttl', query)\n",
        "spark_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "POFX3PPs-zld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c2e7119-e48e-4636-83dd-aeb1b273afdc"
      },
      "id": "POFX3PPs-zld",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drop the columns where at least %0 element is missing.\n",
            "Drop the rows where at least %100 element is missing.\n",
            "+--------------------------------------------------------+\n",
            "|recipe                                                  |\n",
            "+--------------------------------------------------------+\n",
            "|http://purl.org/recipekg/recipe/peanut-butter-tandy-bars|\n",
            "|http://purl.org/recipekg/recipe/the-best-oatmeal-cookies|\n",
            "|http://purl.org/recipekg/recipe/peach-cobbler-ii        |\n",
            "+--------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3646b987",
      "metadata": {
        "id": "3646b987"
      },
      "source": [
        "## Feature Engineering\n",
        "\n",
        "Let's get more information about the recipes.\n",
        "After acquiring the data, we can use the `getFeatures` function to extract features and their descriptions from the Spark DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "# Specify the SPARQL endpoint and query\n",
        "query2 =\"\"\"\n",
        "     PREFIX schema: <https://schema.org/>\n",
        "     PREFIX recipeKG:<http://purl.org/recipekg/>\n",
        "     PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "     SELECT DISTINCT ?recipe ?calorie ?category ?USDAScore\n",
        "     WHERE {\n",
        "                 ?recipe a schema:Recipe.\n",
        "\n",
        "                 ?recipe recipeKG:hasNutritionalInformation ?a.\n",
        "                 ?a recipeKG:hasCalorificData ?b.\n",
        "                 ?b recipeKG:hasAmount ?calorie.\n",
        "\n",
        "                 ?recipe recipeKG:belongsTo ?subcategory.\n",
        "                 ?subcategory rdfs:subClassOf* ?category.\n",
        "                 ?category a recipeKG:RecipeCategory.\n",
        "\n",
        "                 ?recipe recipeKG:hasUSDAScore ?USDAScore.\n",
        "         }\n",
        "         LIMIT 10\n",
        "     \"\"\"\n",
        "\n",
        "# Retrieve the data as a Spark DataFrame\n",
        "spark_df = dataAcquisitionObject.query_local_rdf(\"recipekg_100.ttl\",'turtle', query2)\n",
        "#let's also delete the url and just have names\n",
        "spark_df = spark_df.withColumn(\"recipe\", regexp_replace('recipe','http://purl.org/recipekg/recipe/',''))\n",
        "spark_df = spark_df.withColumn(\"category\", regexp_replace('category','http://purl.org/recipekg/categories/',''))\n",
        "spark_df = spark_df.withColumn(\"category\", regexp_replace('category','/',''))\n",
        "spark_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPSWhqCmDTpn",
        "outputId": "19139c7b-70b8-4bc6-a46b-942aa94b1254"
      },
      "id": "aPSWhqCmDTpn",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drop the columns where at least %0 element is missing.\n",
            "Drop the rows where at least %100 element is missing.\n",
            "+--------------------------------------------+-------+-------------------------------+---------+\n",
            "|recipe                                      |calorie|category                       |USDAScore|\n",
            "+--------------------------------------------+-------+-------------------------------+---------+\n",
            "|peanut-butter-tandy-bars                    |230.0  |desserts                       |3        |\n",
            "|the-best-oatmeal-cookies                    |172.8  |desserts                       |4        |\n",
            "|peach-cobbler-ii                            |672.4  |desserts                       |1        |\n",
            "|pie-crust-v                                 |210.4  |desserts                       |3        |\n",
            "|dads-beef-and-chive-dip                     |77.6   |appetizers-and-snacks          |4        |\n",
            "|palak-paneer-indian-spinach-and-paneer      |315.1  |trusted-brands-recipes-and-tips|4        |\n",
            "|corn-and-porcini-mushroom-cornbread-dressing|214.7  |side-dish                      |3        |\n",
            "|easy-mexican-fried-chicken                  |548.1  |meat-and-poultry               |3        |\n",
            "|orange-raisin-cake                          |168.2  |desserts                       |4        |\n",
            "|onion-masala-omelette                       |522.3  |breakfast-and-brunch           |4        |\n",
            "+--------------------------------------------+-------+-------------------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "3b009366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b009366",
        "outputId": "bac0b594-c921-405c-8226-0c05c4ae3ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No entity column has been set, that is why the first column recipe is used as entity column\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'calorie': {'featureType': 'Single_NonCategorical_Double',\n",
              "  'name': 'calorie',\n",
              "  'nullable': False,\n",
              "  'datatype': DoubleType(),\n",
              "  'numberDistinctValues': 10,\n",
              "  'isListOfEntries': False,\n",
              "  'isCategorical': False},\n",
              " 'category': {'featureType': 'Single_NonCategorical_String',\n",
              "  'name': 'category',\n",
              "  'nullable': False,\n",
              "  'datatype': StringType(),\n",
              "  'numberDistinctValues': 6,\n",
              "  'isListOfEntries': False,\n",
              "  'isCategorical': False},\n",
              " 'USDAScore': {'featureType': 'Single_NonCategorical_Long',\n",
              "  'name': 'USDAScore',\n",
              "  'nullable': False,\n",
              "  'datatype': LongType(),\n",
              "  'numberDistinctValues': 3,\n",
              "  'isListOfEntries': False,\n",
              "  'isCategorical': False}}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from sparkkgml.feature_engineering import FeatureEngineering\n",
        "\n",
        "# Create an instance of FeatureEngineering\n",
        "featureEngineeringObject = FeatureEngineering()\n",
        "\n",
        "# Extract features\n",
        "df2, features = featureEngineeringObject.getFeatures(spark_df)\n",
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11afebaf",
      "metadata": {
        "id": "11afebaf"
      },
      "source": [
        "## Vectorization\n",
        "\n",
        "Next, we can vectorize the features we extracted using the `vectorize` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "36c188dd",
      "metadata": {
        "id": "36c188dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab32ba6-40ec-4d49-a262-b532d01050bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No entity column has been set, that is why the first column recipe is used as entity column\n",
            "+--------------------+-------+--------------------+---------+\n",
            "|              recipe|calorie|            category|USDAScore|\n",
            "+--------------------+-------+--------------------+---------+\n",
            "|corn-and-porcini-...|  214.7|[0.06451535224914...|        3|\n",
            "|dads-beef-and-chi...|   77.6|[-0.1662092804908...|        4|\n",
            "|easy-mexican-frie...|  548.1|[0.06132638454437...|        3|\n",
            "|onion-masala-omel...|  522.3|[-0.0420703291893...|        4|\n",
            "|  orange-raisin-cake|  168.2|[0.11072149872779...|        4|\n",
            "+--------------------+-------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sparkkgml.vectorization import Vectorization\n",
        "\n",
        "# Create an instance of Vectorization\n",
        "vectorizationObject = Vectorization()\n",
        "\n",
        "# Vectorize the DataFrame\n",
        "digitized_df = vectorizationObject.vectorize(df2, features)\n",
        "digitized_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "251e250b",
      "metadata": {
        "id": "251e250b"
      },
      "source": [
        "## Semantification\n",
        "\n",
        "Finally, we will use the `semantify` function to convert the DataFrame results into RDF data in Turtle format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9ac69b8f",
      "metadata": {
        "id": "9ac69b8f"
      },
      "outputs": [],
      "source": [
        "from sparkkgml.semantification import Semantification\n",
        "\n",
        "# Create an instance of Semantification\n",
        "semantificationObject = Semantification()\n",
        "\n",
        "# Semantify the data\n",
        "semantificationObject.semantify(df2, namespace=\"http://purl.org/recipekg/recipe/\", exp_uri=\"recipe\", exp_label=\"USDAScore\", exp_prediction=\"USDAScore\", dest=\"output.ttl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd8d018e",
      "metadata": {
        "id": "fd8d018e"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, we installed SparkKG-ML, retrieved data from a SPARQL endpoint, performed feature engineering, vectorized the data, and finally semantified the machine learning results. This demonstrates how SparkKG-ML facilitates a complete machine learning pipeline with semantic web and knowledge graph data.\n",
        "\n",
        "Feel free to explore the additional functionalities in the SparkKG-ML documentation.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}